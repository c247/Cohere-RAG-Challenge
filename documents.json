[
  {
    "title: ": 1,
    "snippet": "The host of CS350 gives an introduction to the course and outlines the new lecture times. They go over their background, explaining they are a lecturer at Waterloo and their research area is in computer graphics, specifically in stereo 3D and pre-visualization and post-production algorithms. The lecturer also explains why there are so many graphics experts teaching operating systems courses. The course will be conducted entirely online, and the instructor goes over the course website and Piazza, where all communications will take place. The instructor also mentions the grading scheme and the course policies. The course is focused on C programming and using a simulated MIPS architecture, therefore only specific libraries can be used. The instructor recommends reviewing C programming and memory management concepts. Previous midterms, review questions, and solutions are available on the course website for students to practice with."
  },
  {
    "title: ": 2,
    "snippet": "In this episode, the instructor provides updates on the course website, encourages students to use Piazza for communication, and offers tips for troubleshooting issues with VS Code and OS161. The instructor also discusses the history of operating systems, highlighting the GMNAIO operating system from the 1950s, and provides insights into the use of FORTRAN in government and space applications. Moving on to the topic of threads, the instructor describes the concept of concurrency and explains the importance of practical experience in threading using the PThreads library. The episode concludes with a brief overview of the concept of threads and their role in concurrent programming. \n\nWould you like me to help you with anything else regarding this episode's content?"
  },
  {
    "title: ": 3,
    "snippet": "In this episode, we discuss how to have multiple threads sharing a single CPU while making the user believe that all those threads are actually executing at the same time. We look at the details of how this is done, and we also discuss how to debug OS 161. We then introduce the operating system of the day, which is exec one, released in 1962 for the univac 1107. It offered multi-programming and solid state memory, and was optimized for fortran. The machine had a word size of 36 bits, and could store 65,000 of them, for a total of 288 kilobytes of memory. SSDs gained popularity in the 2010s due to improved technology, but the concept is not new, as solid state memory has been around since the 1960s. However, at the time, technology was expensive and not very large, so there wasn't much progress made. We then discuss the difference between a thread and a process, before moving on to look at how to implement time sharing in OS 161."
  },
  {
    "title: ": 4,
    "snippet": "In this episode, the concept of context switching is discussed in the context of multi-threading in operating systems. The need for context switching arises from the fact that multiple threads share a single CPU and we want to give the user the illusion that all threads are making progress simultaneously. There are four reasons why a context switch might occur: thread yield, thread exit, blocking, and preemption. The context switch is performed by saving the context of the current thread onto its stack and loading the context of the next thread onto the CPU. An example is presented using two threads, one which runs indefinitely and one which yields the CPU periodically to allow the other thread to run. The concept of cooperative concurrency is also introduced, where a thread voluntarily yields the CPU to allow other threads to run. \n\nThe OS of the day is MCP, also known as the Master Control Program, which was released in 1961 by the Burroughs Corporation. It was written in a high-level language called Espol, which was an extension of the Algol programming language. MCP was the first operating system to be written in a high-level language and the first to commercially implement virtual memory. It also supported multiple processing units and multi-programming."
  },
  {
    "title: ": 5,
    "snippet": "In this episode, the consequences of using multi-threads in an application are discussed in detail. The primary focus is on the synchronization module, specifically locks and lock use. The importance of using the pthreads library for assignment one to gain experience with threading in the real world is emphasized, and the benefits of using a proper thread library are highlighted. The dangers of using pthread join are discussed, as it is important to use synchronization primitives to mimic the behavior of join. The operating system of the day is CTSS, which is the first operating system that demonstrated the concept of time-sharing, which is what allows for the use of multi-threading. The importance of finding the right balance between the number of threads created and the amount of work given to each thread is stressed, as too many threads with short jobs can lead to wasted time on managing the threads rather than doing work. CTSS is also credited for bringing several advancements to the table, such as text formatting utilities and the first user messaging program, which is the predecessor to email. The predecessor of Unix, Multix, is also derived from CTSS."
  },
  {
    "title: ": 6,
    "snippet": "In this episode, Leslie continues the discussion on synchronization by looking at locks, semaphores, and condition variables. Locks are a synchronization mechanism used to enforce mutual exclusion, meaning that only one thread can access a critical section of code at a time. Leslie explains the concept of race conditions and how they can be avoided by using locks to ensure that only one thread can access the critical section. She then discusses the load-link and store-conditional instructions, which are hardware-based operations that can be used to implement locks efficiently. \n\nAdditionally, Leslie reviews the design of dtss (Dartmouth Time-Sharing System), which was an early example of a large-scale time-sharing system. The main goal of dtss was to demonstrate the feasibility of time-sharing on a large scale, and it successfully achieved this goal by achieving 80% usage by 1968. The system enforced a maximum response time of 10 seconds for each operation, and it used an integrated design environment that allowed developers to write, compile, and execute code within a single environment. \n\nThe episode ends with a review of the load-link and store-conditional instructions and how they can be used to implement locks."
  },
  {
    "title: ": 7,
    "snippet": "In this episode, the implementation of semaphores is discussed in further detail. The difference between locks and spin locks is clarified, and the purpose of each is explained. The episode also covers the history of Multix, a predecessor of Unix, and some of its unique features, such as single-level storage and dynamic linking. Additionally, the difference between semaphores, locks, and binary semaphores is explained, and it is noted that semaphores are not meant to be used the same way as locks. The episode ends with a discussion of the producer-consumer problem, a common use case for semaphores, and why it is beneficial to take a concurrency course. \n\nWhat is a semaphore?: A semaphore is a synchronization primitive that is used to coordinate access to a shared resource among multiple threads. It allows threads to take turns accessing the resource, ensuring that only one thread can access it at a time. \n\nHow does it work?: A semaphore maintains a counter that represents the number of available resources. When a thread wants to access the resource, it tries to acquire a semaphore by decrementing the counter."
  },
  {
    "title: ": 8,
    "snippet": "In this episode, Leslie wraps up the discussion on synchronization by talking about other sources where race conditions can appear. She talks about the operating system called OS 360, its failure to achieve its goals, and its popularity for a short period due to its editor and debugger. She also answers questions from Twitch about interrupts and spam clicking, and why sometimes spam clicking can wake up a frozen computer. Lastly, she goes over the concept of condition variables, their function, and their use in solving the producer-consumer problem. \n\n**Readings:**\n- None\n**Additional Resources:** \n- \"OS 360: A Failure in Distributed Computing\" by Jeffery Stutzke, Communications of the ACM, Volume 21, Number 7, July 1978\n- \"A Brief History of Multitasking\" by David A. Curry, Communications of the ACM, Volume 7, Number 12, December 1964\n- \"Condition Variables\" by Richard Stevens, Addison-Wesley Longman Publishing Co., Inc."
  },
  {
    "title: ": 9,
    "snippet": "In this episode, the professor discusses the operating system process. She begins by giving a brief history of Unix and explains why its developers created it. She also explains the difference between a process and a thread, stating that a process is an execution environment, and a thread is an execution tool. Then she goes over the parts of a process, such as its address space, thread array, and vnode. She mentions that a process structure is created and managed by the kernel. She also warns that process names are not guaranteed to be unique and should not be used for checking. She then shows code from an operating system kernel and explains what each part does. \n\nNote: This transcript is automatically generated and may contain errors. Please check the corresponding audio before quoting. \n\n## Resources\n\n[Univ of Washington: The Evolution of Unix and Its Influence on Linux](https://www.cs.washington.edu/education/courses/cse120/14sp/lectures/14univ-unix.pdf)\n\n[Wikipedia: History of Unix](https://en.wikipedia."
  },
  {
    "title: ": 10,
    "snippet": "In this episode, we continue the discussion on processes. More specifically, we talk about process management calls and how they get executed within the kernel. We look at an example of a process structure and the functions associated with it. We then look at system calls and how they relate to processes. We also look at the difference between unprivileged and privileged code and how they can affect the CPU. \n\nPick was a major competitor to Unix in the 1980s, yet few people have heard of it today. Pick was based on a database, and it had a hash-based database system built into its kernel. It supported multiple users, time-shared concurrency, and demand paging virtual memory. Pick is still in use today as a database environment that can run on top of operating systems like Windows. \n\nFor assignment 2, we will be filling in the missing parts of the process structure in the OS161 implementation. We covered creating a process with the fork function, and we looked at some other process management calls. We also covered the parent-child relationship of processes and threads. \n\nIn the next episode, we will continue our discussion of system calls and the difference between unprivileged and privileged code."
  },
  {
    "title: ": 11,
    "snippet": "In this episode of CS350 Online, the focus is on discussing assignment 2, which has been recently combined from two separate assignments (a2a and a2b) into one. The instructor emphasizes the importance of starting the assignment early, as debugging synchronization and deadlock issues can be time-consuming. To assist with debugging, a Piazza post is referenced that highlights common errors and memory issues. The episode then introduces Alto Executive, an operating system developed at Xerox Park in 1973. Alto Executive is noted for its features such as time-sharing, concurrency, and Ethernet support. The introduction of a mouse-operated desktop environment in Alto Executive broke the isolation between kernel and user programs, allowing user applications to access the underlying microcodes for optimization. The episode concludes with a discussion of the implementation of locks and condition variables, which are prerequisites for attempting the other parts of the assignment. Testing locks is important to ensure statistical certainty, and using the semaphore implementation as a guide is recommended. For condition variables, it is crucial to initialize all fields and use lock do I hold in cv weight. Avoid adding spin locks or running tests back-to-back in OS161."
  },
  {
    "title: ": 12,
    "snippet": "In this episode, the concept of virtual memory is introduced. The address space, address translation, and segmentation are discussed. It is recommended that students start working on assignment 2 as early as possible because it takes a long time to debug. The most common errors from assignment 2 are also described. After that, the Berkeley Software Distribution (BSD) is introduced, which was released in 1978 for the PDP-11. BSD is a variant of Unix and is the basis for Mac OS X. The episode then focuses on virtual memory, its history, and how address spaces have changed over time. It is noted that all addresses seen in previous courses are fake and that physical addresses were once used to allocate memory for different processes, but this is no longer done. \n\nWould you like me to help you with anything else regarding this episode?"
  },
  {
    "title: ": 13,
    "snippet": "In this episode, we continue our discussion on virtual memory, specifically on a type of virtual memory called paging. We discuss the basic implementation of virtual memory in OS161, and how it can cause funny behavior when running tests. We then look at the virtual memory of OpenVMS, an operating system that has been around since 1977 and is still in active development. OpenVMS is a time-shared, multi-user operating system that supports concurrent processing and has a built-in database, making it ideal for server use. We discuss the history of OpenVMS and its various names, as well as its stability and security features. We also talk about the memory management unit (MMU) and how it performs virtual to physical address translation. We go over the basics of dynamic relocation, where virtual memory is mapped to physical memory in a contiguous manner, and the fragmentation issues that can arise from it. We then talk about segmentation, another method of virtual memory translation that tracks specific segments of the address space. We go over the advantages and disadvantages of segmentation and how it was implemented in early versions of Windows."
  },
  {
    "title: ": 14,
    "snippet": "In this episode, we discuss different methods for improving the performance of multi-level paging. We explain why multi-level paging is used instead of a single level page table and go over the different levels of page tables in a multi-level system. Then we talk about the different ways to lay out the page tables in memory and why we choose to do it that way. We finish up by going over some sample problems on paging. \n\nThe sun microsystems, also known as solaris, was released in 1982. It was popular because it was the first company to market with the 64-bit processor. Many computer scientists and data scientists were in need of this as 32 bits wasn't enough anymore. Sun died because they had proprietary hardware and a proprietary operating system. Most people opted for cheaper hardware and consumer operating systems, like linux, that were easier to maintain. \n\nWe go over the basics of multi-level paging, including why we use it instead of a single level page table and how to search the page tables. We then talk about some improvements to multi-level paging, such as ways to reduce search time."
  },
  {
    "title: ": 15,
    "snippet": "In this episode, Leslie continues the discussion on virtual memory, focusing on on-demand paging. She provides insights into the QNX operating system, its history, and how it is used today. Leslie also covers the translation look-aside buffer (TLB) and its role in reducing the time needed for translation. She explains the differences between hardware-managed and software-managed TLBs, their advantages, and disadvantages. She then discusses the format of the MIPS TLB and the process of evicting entries from the TLB when it is full. Additionally, she touches on the concept of cache affinity and how it can improve performance. Throughout the episode, Leslie emphasizes the importance of understanding the basics of virtual memory and how it works in operating systems. She encourages listeners to experiment with virtual memory settings and addresses common errors encountered in assignment 2."
  },
  {
    "title: ": 16,
    "snippet": "In this episode, the focus is on scheduling, with special attention given to the historical disc operating system (DOS). Several key features of DOS are highlighted, including its limited processing power, lack of multitasking capabilities, and basic command-line interface. The episode also explores the concept of job scheduling in operating systems, touching on response time, turnaround time, and the assumptions made in scheduling algorithms. The episode concludes with a brief overview of multi-core scheduling, suggesting that there are more complexities involved in modern operating systems. \n\nWould you like me to help you summarize something else you've heard on the podcast?"
  },
  {
    "title: ": 17,
    "snippet": "In this episode of cs350 online, the instructor apologizes for audio issues and explains the issue with their microphone. The instructor then gives an overview of the history of OS2, and how it was meant to be an upgrade from DOS, and how it supported features such as protected mode, virtualization, and a GUI. The instructor then talks about devices, and how they can be either input, output, or both, such as keyboards, mice, touch screens, and microphones. The instructor then explains the importance of the clock as a device, and how it is responsible for implementing preemptive concurrency. The instructor then talks about other devices such as disk drives, SSDs, and network cards. The instructor then shows the terminal and the /dev directory, and explains how in Unix-based systems, devices are treated as files, and gives an example of printing to a printer via a serial port. \n\nWould you like me to help you with anything else regarding this summary?"
  },
  {
    "title: ": 18,
    "snippet": "In this episode, the focus is on disk drives and their drivers. The OS of the day is Minix, which was created in 1987 by Andrew S. Tanenbaum. Minix was designed to be a miniature version of Unix, as Unix contains a lot of features in its kernel. The original kernel of Minix was only 12,000 lines of code, which included the kernel, file system, and memory management. Minix was also designed to be self-healing, which is the ability to restart a driver without affecting the running process. This is something that shows up in most operating systems now. The concept of self-healing came from the idea that device drivers often crash and can take down the whole system. Minix was the inspiration for Linux, and Linus Torvalds used Minix to create the Linux kernel. \n\nThe episode then moves on to discuss device drivers and how they interact with devices. Devices are usually thought of as external attachments to a computer, but there are many internal devices as well, such as the clock. Devices have device drivers, which are used to interact with the device. Device drivers use device registers to tell the device to do something or to find out information about the device."
  },
  {
    "title: ": 19,
    "snippet": "In this episode of CS350 Online, the instructor covers Assignment 3, which focuses on virtual memory management in OS161. Virtual memory allows programs to run in different memory locations, creating a separation between user programs and the operating system. However, there are issues with the current implementation of virtual memory in OS161, such as the lack of a proper page replacement algorithm and the inability to run programs consecutively due to a full translation look-aside buffer (TLB). The assignment requires students to address these issues by implementing a least-recently used (LRU) page replacement algorithm and enabling the execution of multiple programs consecutively. The instructor provides insights into the assignment requirements, highlights the importance of specific tasks, and offers recommendations for efficient time management. Students are encouraged to focus on the critical aspects of the assignment, such as fixing the TLB eviction problem and handling the code segment permissions, while prioritizing their time to ensure completion within the given deadline. The instructor also mentions that none of the assignment tests require argument passing, so students can prioritize their efforts accordingly."
  },
  {
    "title: ": 20,
    "snippet": "In this episode of cs350 online, the instructor begins teaching a new topic, File Systems. The focus of the episode is Windows, and its release history and versions. The instructor also mentions the two types of Windows operating systems: DOS-based and not DOS-based. The episode ends with a summary of Windows releases from 1985 to 2000, and a comparison between the consumer and commercial versions of Windows. \n\nWould you like me to help you with anything else regarding Windows?"
  },
  {
    "title: ": 21,
    "snippet": "In this episode, the host discusses virtual file systems and physical file systems. She begins by apologizing for the delay in the recording due to a power outage and recommends that listeners use a UPS to protect against power outages. The host then introduces the topic of the day, the Linux kernel, and provides a brief history of its development. She explains the layers of abstraction in the Linux kernel and how it handles memory management, virtual memory, IPC, and file systems. The host also describes the various distributions of Linux and her experience using different versions. She then discusses the concept of virtual file systems, how they allow multiple physical file systems to appear as a single logical file system, and the differences between Windows and Unix-based systems in handling virtual file systems. The episode concludes with a brief overview of physical file systems, such as Ext4, NTFS, and APFS, and how they are presented to the logical file system. \n\nWould you like me to help you with anything else?"
  },
  {
    "title: ": 22,
    "snippet": "In this episode, we discuss file systems in depth. Specifically, we cover Android and iOS. We go over the basics of each mobile operating system and how they differ from each other. We also discuss the history of each operating system. There is also a quick reminder of the upcoming assignment due date. \n\nThe main topic of discussion is File Systems. We go over the basics of File Systems. We also discuss the differences and similarities between Disk-based and Memory-based File Systems. After that, we get into the details of Disk-based File Systems. We explain the layout of Disk Blocks, Inodes, and Super Blocks. \n\nThe episode ends with a summary of the previous episode on File System Implementations and goes over the topics that will be covered in the next episodes. \n\nThe reading assignment for Episode 22 is File Systems: Overview and Design, Chapter 6: File System Implementation. \n\nThe reference for this episode is:\nBing N. Venkatraman, File Systems: Design and Implementation, Pearson Education, 2004. \n\nThe timestamp for this episode is Friday, July 30, 2021, at 12:00pm PST."
  },
  {
    "title: ": 23,
    "snippet": "In this episode, the instructor provides a brief overview of virtual machines, including what they are and why they are used. The instructor then highlights the importance of reading assignments and learn quizzes, and encourages students to complete them by the due date. The instructor also mentions assignment three, and clarifies that students are not responsible for implementing page tables. The instructor then introduces Temple OS, a single-user, single-tasking operating system created by Terry Davis. Davis was inspired by a manic episode to create an operating system that would be God's official temple, and the operating system has some very unique characteristics, such as a 640 x 480 screen resolution, 16 colors, and no network capability. The instructor notes that Temple OS is a very interesting operating system from a technical perspective and encourages students to explore its unique features. The instructor then discusses the different types of virtual machines, including emulated computers, simulated computers, and virtual machines that run on a different architecture. The instructor also talks about the importance of virtual machines in learning about operating systems and mentions that sys161, which students have been using to run OS161, is a kind of virtual machine."
  },
  {
    "title: ": 24,
    "snippet": "In this episode of CS350 Online, the professor covers networking and its integration with the operating system. She mentions that there are two models of networking, the 7-layer model and the 5-layer model, but she prefers the 5-layer model as it is more simplified. The 5 layers of the model include the application layer, the transport layer, the network layer, the data link layer, and the physical layer. For most internet users, it is the application layer that they interact with the most. This layer contains protocols for different forms of communication, such as HTTP, FTP, and SMTP. When it comes to operating systems, the application layer lives in user land and does not have any privileges to access kernel functions. \n\nThe transport layer is the layer that is responsible for sending and receiving data for the actual applications, and it lives below the application layer. \n\nShe also mentions that there will be a final exam covering networking and operating systems, and it will be open-book, but no collaboration will be allowed. The exam will have three attempts and will open on August 7th and close on August 16th. \n\nShe also reminds students to complete the quizzes on Learn as they are due soon."
  },
  {
    "title: ": 25,
    "snippet": "In this episode, the instructor gives a final wrap-up of the course. The instructor reminds students that the Page Table Bonus is due tomorrow and that the quizzes are also due tomorrow. The instructor then gives details about the final assessment: it will be another quiz on Learn with somewhere between 60 and 70 questions to answer in three or four hours. The instructor advises not to worry about the number of decimal places in precision since there is an epsilon built in to give full points if the range is considered. The instructor then talks about Temple OS, an operating system released in 2013 by Terry Davis. Davis was an atheist who believed that God spoke to him in a dream and told him to create an operating system that would be God's official temple. Temple OS has quirks in its design as a result of its origins such as a 640 by 480 screen, one audio voice, and no network. The instructor notes that Temple OS actually has modern features such as support for multi-core and preemptive concurrency. The instructor notes that the interesting aspects of Temple OS are its address space and the fact that everything runs with kernel privilege. The instructor notes that this makes processes able to communicate with each other directly, but also has some serious downsides."
  }
]